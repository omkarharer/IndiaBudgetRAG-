{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b160ed31-9af0-486e-936d-f411257faed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0334ed-d517-47b8-ae40-2bcb2696ee93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Chatbot.........\n",
      "Updating the vector database with new documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omkar\\AppData\\Local\\Temp\\ipykernel_23304\\3988637906.py:40: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Omkar\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omkar\\AppData\\Local\\Temp\\ipykernel_23304\\3988637906.py:41: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_db = Chroma(persist_directory='./chroma_db', embedding_function=embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new documents to add.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Take care of yourself, goodbye!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Human:  summary of the budget\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: <think>\n",
      "Okay, so I need to summarize the budget for 2025-26 based on the information provided. Let me go through the details step by step.\n",
      "\n",
      "First, the total receipts other than borrowings are estimated at ₹34.96 lakh crore. That's a significant figure. Then, the total expenditure is ₹50.65 lakh crore. So, the government is spending more than it's receiving, which makes sense because there's a fiscal deficit mentioned.\n",
      "\n",
      "The net tax receipts are ₹28.37 lakh crore. That's a key part of the receipts. Now, the fiscal deficit is 4.4% of GDP. I remember that the previous year's revised estimate was 4.8%, so this is a slight improvement, moving towards the fiscal deficit target.\n",
      "\n",
      "To finance this deficit, the government plans to borrow ₹11.54 lakh crore through net market borrowings from dated securities. The rest of the financing will come from other sources, but the exact details aren't provided here.\n",
      "\n",
      "Looking at the objectives of the budget, it's focused on accelerating growth, inclusive development, encouraging private investments, uplifting household sentiments, and enhancing the spending power of the middle class. These are all positive goals that should support economic stability and growth.\n",
      "\n",
      "The speech also mentions some cess and surcharges, like the Agriculture Infrastructure and Development Cess (AIDC) and the Social Welfare Surcharge (SWS), but it's noted that these are minor changes. The revised estimates for 2024-25 show that the government spent more than initially planned, with a fiscal deficit of 4.8%, which is higher than the budget estimate.\n",
      "\n",
      "Putting this all together, the summary should highlight the key figures: receipts, expenditures, tax receipts, fiscal deficit, borrowing plans, and the overall objectives. It should also note the slight improvement in the fiscal deficit from the previous year and the focus areas of the budget.\n",
      "\n",
      "I need to make sure the summary is clear and concise, covering all these points without getting too bogged down in the numbers. Maybe start with the main estimates, then move to the fiscal deficit and borrowing, followed by the budget's goals, and end with the revised estimates from the previous year.\n",
      "\n",
      "I should also ensure that the summary flows well and is easy to understand, avoiding too much jargon. Maybe use bullet points or sections to break it down, but since the user didn't specify, a paragraph form should suffice.\n",
      "\n",
      "Wait, the user provided a sample summary which is quite detailed. I should make sure mine is similar in structure but in my own words. I'll start by stating the main figures, then the fiscal deficit, how it's financed, the objectives, and then the revised estimates.\n",
      "\n",
      "I think that's a solid approach. Now, I'll draft the summary accordingly, making sure to include all the key points without missing any important details.\n",
      "</think>\n",
      "\n",
      "The Budget for 2025-26 presents a comprehensive financial plan with a focus on economic growth and social development. The total receipts, excluding borrowings, are estimated at ₹34.96 lakh crore, while the total expenditure is ₹50.65 lakh crore, indicating a significant investment in public spending. Net tax receipts amount to ₹28.37 lakh crore, a crucial component of the government's revenue.\n",
      "\n",
      "The fiscal deficit is projected at 4.4% of GDP, showing a slight improvement from the previous year's 4.8%. To address this deficit, the government plans to borrow ₹11.54 lakh crore through market borrowings, with additional financing from other sources.\n",
      "\n",
      "The budget's objectives include accelerating economic growth, promoting inclusive development, stimulating private sector investments, and enhancing the spending power of the middle class. These goals aim to foster economic stability and prosperity.\n",
      "\n",
      "In the previous fiscal year, the revised estimates revealed a fiscal deficit of 4.8%, with total expenditure exceeding initial projections. This underscores the government's commitment to adjusting its financial plans to meet economic challenges.\n",
      "\n",
      "Overall, the budget for 2025-26 balances fiscal prudence with strategic investments, aiming to drive sustainable growth and improve the quality of life for citizens.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "import hashlib\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.chat_models import ChatGroq\n",
    "\n",
    "def initialize_llm():\n",
    "    llm = ChatGroq(\n",
    "        temperature=0,\n",
    "        groq_api_key=\"API-KEY\",\n",
    "        model_name=\"deepseek-r1-distill-llama-70b\"  #llama-3.3-70b-versatile\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "def hash_file_content(filepath):\n",
    "    \"\"\"Generate a hash for the content of a file.\"\"\"\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        return hashlib.md5(file.read()).hexdigest()\n",
    "\n",
    "def create_vector_db():\n",
    "    loader = DirectoryLoader(\"data/\", glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    text = text_splitter.split_documents(documents)\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma.from_documents(text, embeddings, persist_directory='./chroma_db')\n",
    "    vector_db.persist()\n",
    "\n",
    "    print(\"ChromaDB created and data saved.\")\n",
    "    return vector_db\n",
    "\n",
    "def update_vector_db():\n",
    "    \"\"\"Only add new documents to the vector database.\"\"\"\n",
    "    # Initialize database and retriever\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vector_db = Chroma(persist_directory='./chroma_db', embedding_function=embeddings)\n",
    "    \n",
    "    # Load existing metadata\n",
    "    existing_metadata = {doc.metadata.get(\"file_hash\", \"\") for doc in vector_db.similarity_search(\"\", k=vector_db._collection.count())}\n",
    "\n",
    "    # Load new documents\n",
    "    loader = DirectoryLoader(\"data/\", glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Filter out already processed files\n",
    "    new_docs = []\n",
    "    for doc in documents:\n",
    "        file_hash = hash_file_content(doc.metadata[\"source\"])\n",
    "        if file_hash not in existing_metadata:\n",
    "            doc.metadata[\"file_hash\"] = file_hash  # Add hash to metadata\n",
    "            new_docs.append(doc)\n",
    "    \n",
    "    # Add only new documents to the vector DB\n",
    "    if new_docs:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        text = text_splitter.split_documents(new_docs)\n",
    "        vector_db.add_documents(text)\n",
    "        vector_db.persist()\n",
    "        print(f\"Added {len(new_docs)} new documents to the vector database.\")\n",
    "    else:\n",
    "        print(\"No new documents to add.\")\n",
    "    \n",
    "    return vector_db\n",
    "\n",
    "def setup_qa_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt_templates = \"\"\"You are an expert financial analyst specializing in the Indian Budget. Provide clear, insightful, and data-driven responses to the following question:  \n",
    "    {context}  \n",
    "    User: {question}  \n",
    "    BudgetBot:\"\"\"\n",
    "\n",
    "    PROMPT = PromptTemplate(template=prompt_templates, input_variables=['context', 'question'])\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": PROMPT}\n",
    "    )\n",
    "    return qa_chain\n",
    "\n",
    "def main():\n",
    "    print(\"Initializing Chatbot.........\")\n",
    "    llm = initialize_llm()\n",
    "    db_path = \"./chroma_db\"\n",
    "\n",
    "    if not os.path.exists(db_path):\n",
    "        print(\"Creating a new vector database...\")\n",
    "        vector_db = create_vector_db()\n",
    "    else:\n",
    "        print(\"Updating the vector database with new documents...\")\n",
    "        vector_db = update_vector_db()\n",
    "    \n",
    "    qa_chain = setup_qa_chain(vector_db, llm)\n",
    "\n",
    "    while True:\n",
    "        query = input(\"\\nHuman: \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Chatbot: Take care of yourself, goodbye!\")\n",
    "            break\n",
    "        response = qa_chain.run(query)\n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c9160d-1443-413f-b426-c5e8a61cf39a",
   "metadata": {},
   "source": [
    "# weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ebcaa1-d97f-42fe-ba99-c7aa74f2aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install weaviate-client\n",
    "# !pip install langchain\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717916d-b40e-4cba-97d6-bc223039fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=\"API-KEY\"\n",
    "WEAVIATE_URL=\"URL\"\n",
    "WEAVIATE_API_KEY=\"API-KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d92f3cb-013b-4051-8598-3f430fa1cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"data/\", glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6a5580-c3b2-4021-b4a9-44a2077f595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_documents(data)\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4493433b-7dbe-44af-aaa4-d984d47b6812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query(\"what is you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e386457-4d28-473e-8131-55eacad3cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the page_content from the Document objects\n",
    "texts = [t.page_content for t in text_chunks]\n",
    "\n",
    "# Step 3: Initialize the HuggingFaceBgeEmbeddings model\n",
    "embedding_model = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 4: Generate embeddings for the text chunks\n",
    "embeddings = embedding_model.embed_documents(texts)  # Use .embed_documents()\n",
    "\n",
    "# Debugging: Print the first embedding\n",
    "# print(\"First embedding:\", embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbf48aa-5adf-4a41-a64a-7cb6e8fe6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c453ee5a-a33d-4080-9ba7-3d3d2ab5cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(\n",
    "        api_key=\"API-KEY\"\n",
    "    )\n",
    "\n",
    "index_name = \"rag\" # put in the name of your pinecone index here\n",
    "# Connect to the existing index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dab62d1-2033-49d5-b41c-a58f9d7da182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 6: Prepare vectors for upserting\n",
    "vectors = [\n",
    "    {\n",
    "        \"id\": f\"vec_{i}\",  # Replace with a unique ID for each vector\n",
    "        \"values\": embedding,  # No need to convert to float; it's already a list of floats\n",
    "        \"metadata\": {\"text\": t.page_content}  # Optional: Add metadata (e.g., the text chunk)\n",
    "    }\n",
    "    for i, (t, embedding) in enumerate(zip(text_chunks, embeddings))\n",
    "]\n",
    "\n",
    "# Debugging: Print the first vector to verify its structure\n",
    "# print(\"First vector:\", vectors[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346cf4c1-0656-4891-9a09-c04505f87384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings upserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Upsert the embeddings into the Pinecone index\n",
    "index.upsert(vectors=vectors)\n",
    "\n",
    "print(\"Embeddings upserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac30d84d-b68b-4333-9490-7d5eab58a185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omkar\\AppData\\Local\\Temp\\ipykernel_23304\\3103027569.py:7: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
      "  docsearch = Pinecone(index, embedding_model.embed_query, \"text\")\n",
      "C:\\Users\\Omkar\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "import pinecone  \n",
    "\n",
    "# Initialize Pinecone vector store\n",
    "docsearch = Pinecone(index, embedding_model.embed_query, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb8267ce-7302-4eb8-bfc4-9562466a1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19  \n",
      " \n",
      "Budget Estimates 2025-26 \n",
      "112. Coming to 2025 -26, the total receipts other than  borrowings and the \n",
      "total expenditure are estimated at ` 34.96 lakh crore and ` 50.65 lakh crore \n",
      "respectively. The net tax receipts are estimated at ` 28.37 lakh crore. \n",
      "113. The fiscal deficit is estimated to be 4.4 per cent of GDP. \n",
      "114. To finance the fiscal deficit, the net market borrowings from dated \n",
      "securities are estimated at ` 11.54 lakh crore. The balance financing is expected\n",
      "statement.           \n",
      "Revised Estimates 2024-25 \n",
      "110. The Revised Estimate of the total receipts other than borrowings is  \n",
      "` 31.47 lakh crore, of which the net tax receipts are ` 25.57 lakh crore. The \n",
      "Revised Estimate of the total expenditure is ` 47.16 lakh crore, of which the \n",
      "capital expenditure is about ` 10.18 lakh crore. \n",
      "111. The Revised Estimate of the fiscal deficit is 4.8 per cent of GDP.\n",
      "applicable for income marginally higher than ` 12,00,000.  \n",
      "• A few examples for calculation of tax benefit are given in the table \n",
      "below:\n",
      "CONTENTS \n",
      " \n",
      "PART – A \n",
      " Page No. \n",
      "Introduction 1 \n",
      "Budget Theme 1 \n",
      "Agriculture as the 1st engine 3 \n",
      "MSMEs as the 2nd engine 6 \n",
      "Investment as the 3rd engine 8 \n",
      "A. Investing in People 8 \n",
      "B. Investing in the Economy 10 \n",
      "C. Investing in Innovation 14 \n",
      "Exports as the 4th engine 15 \n",
      "Reforms as the Fuel 16 \n",
      "Fiscal Policy 18 \n",
      " \n",
      " \n",
      "PART – B \n",
      "Indirect taxes 20 \n",
      "Direct Taxes  23 \n",
      " \n",
      "Annexure to Part-A 29 \n",
      "Annexure to Part-B 31\n",
      "46  \n",
      " \n",
      "Annexure to Part B \n",
      "Amendments relating to Direct Taxes \n",
      "(i) Personal Income-tax reforms with special focus on middle class \n",
      "1. Substantial relief is proposed under the new tax regime with new slabs \n",
      "and tax rates as under: - \n",
      " Total income Rate of tax \n",
      "Upto ` 4,00,000 Nil \n",
      "From ` 4,00,001 to ` 8,00,000 5 per cent \n",
      "From ` 8,00,001 to ` 12,00,000 10 per cent \n",
      "From ` 12,00,001 to ` 16,00,000 15 per cent \n",
      "From ` 16,00,001 to ` 20,00,000 20 per cent\n"
     ]
    }
   ],
   "source": [
    "# !pip install pinecone-client langchain\n",
    "# Perform a similarity search\n",
    "query = \"What is the budget allocation for incometax?\"\n",
    "results = docsearch.similarity_search(query, k=5)\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
